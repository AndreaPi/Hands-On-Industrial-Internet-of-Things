q()
library(parallel)
# Calculate the number of cores
no_cores <- detectCores() - 1
# Initiate cluster
cl <- makeCluster(no_cores)
parLapply(cl, 2:4,
function(exponent)
2^exponent)
q()
ds <- read.csv('train_FD001.txt', header = FALSE, sep = "-", dec = ".")
setwd("~/Documents/workspace-iiot/iiot-book/ch13/data")
ds <- read.csv('train_FD001.txt', header = FALSE, sep = "-", dec = ".")
View(ds)
ds <- read.csv('train_FD001.txt', header = FALSE, sep = " ", dec = ".")
library(summarytools)
freq(iris$Species, style = "rmarkdown")
library(summarytools)
freq(ds, style = "rmarkdown")
library(summarytools)
freq(ds[:,1], style = "rmarkdown")
library(summarytools)
freq(ds[,1], style = "rmarkdown")
library(summarytools)
freq(ds$V1, style = "rmarkdown")
library(summarytools)
freq(ds$V3, style = "rmarkdown")
library(summarytools)
descr(ds$V3, style = "rmarkdown")
library(summarytools)
descr(ds, style = "rmarkdown")
view(dfSummary(ds))
print(dfSummary(ds, graph.magnif = 0.8),
method = 'render',
omit.headings = TRUE,
bootstrap.css = FALSE)
install.packages("shiny")
# Define server logic required to generate and plot a random distribution
shinyServer(function(input, output) {
# Expression that generates a plot of the distribution. The expression
# is wrapped in a call to renderPlot to indicate that:
#
#  1) It is "reactive" and therefore should be automatically
#     re-executed when inputs change
#  2) Its output type is a plot
#
output$distPlot <- renderPlot({
# generate an rnorm distribution and plot it
print(dfSummary(ds, graph.magnif = 0.8),
method = 'render',
omit.headings = TRUE,
bootstrap.css = FALSE)
})
})
library(shiny)
# Define server logic required to generate and plot a random distribution
shinyServer(function(input, output) {
# Expression that generates a plot of the distribution. The expression
# is wrapped in a call to renderPlot to indicate that:
#
#  1) It is "reactive" and therefore should be automatically
#     re-executed when inputs change
#  2) Its output type is a plot
#
output$distPlot <- renderPlot({
# generate an rnorm distribution and plot it
print(dfSummary(ds, graph.magnif = 0.8),
method = 'render',
omit.headings = TRUE,
bootstrap.css = FALSE)
})
})
runExample("01_hello")
library(summarytools)
ui <- fluidPage(
titlePanel("dfSummary"),
sidebarLayout(
sidebarPanel(
uiOutput("dfSummaryButton")
),
mainPanel(
tabsetPanel(
tabPanel("dfSummary Output",
htmlOutput("profileSummary")))
)
)
)
server <- function(input, output, session) {
#Read in data file
recVal <- reactiveValues()
dfdata <- iris
#Create dfSummary Button
output$dfSummaryButton <- renderUI({
actionButton("dfsummarybutton", "Create dfSummary")
})
#Apply dfSummary Buttom
observeEvent(input$dfsummarybutton, {
recVal$dfdata <- dfdata
})
#dfSummary data
output$profileSummary <- renderUI({
req(recVal$dfdata)
SumProfile <- print(dfSummary(ds, graph.magnif = 0.8),
method = 'render',
omit.headings = TRUE,
bootstrap.css = FALSE)
SumProfile
})
}
shinyApp(ui, server)
library(readr)
install.packages("readr")
readr
library(magrittr)
# chunk options
opts_chunk$set(warning = FALSE,
message = FALSE,
echo    = FALSE,
fig.align  = "center",
fig.width  = 15,
fig.height = 12)
file_name <- "train_FD001.txt"
data_path <- file.path(data_dir, file_name)
train_set <- read_table2(data_path, col_names = FALSE, col_types = cols(X27 = "_"))
glimpse(train_set)
file_name <- "train_FD001.txt"
data_path <- file.path("../data", file_name)
train_set <- read_table2(data_path, col_names = FALSE, col_types = cols(X27 = "_"))
glimpse(train_set)
library(readr)
file_name <- "train_FD001.txt"
data_path <- file.path("../data", file_name)
train_set <- read_table2(data_path, col_names = FALSE, col_types = cols(X27 = "_"))
glimpse(train_set)
library(knitr)
library(readr)
library(ggplot2)
library(tools)
library(magrittr)
library(skimr)
library(dplyr)
library(tidyr)
library(viridis)
file_name <- "train_FD001.txt"
data_path <- file.path("../data", file_name)
train_set <- read_table2(data_path, col_names = FALSE, col_types = cols(X27 = "_"))
glimpse(train_set)
install.packages('viridis')
install.packages('tidyr')
install.packages('skimr')
install.packages('dplyr')
# chunk options
opts_chunk$set(warning = FALSE,
message = FALSE,
echo    = FALSE,
fig.align  = "center",
fig.width  = 15,
fig.height = 12)
file_name <- "train_FD001.txt"
data_path <- file.path("../data", file_name)
train_set <- read_table2(data_path, col_names = FALSE, col_types = cols(X27 = "_"))
glimpse(train_set)
install.packages('dplyr')
# set random seed for reproducibility
set.seed(1024)
file_name <- "train_FD001.txt"
data_path <- file.path("../data", file_name)
train_set <- read_table2(data_path, col_names = FALSE, col_types = cols(X27 = "_"))
glimpse(train_set)
library(dplyr)
file_name <- "train_FD001.txt"
data_path <- file.path("../data", file_name)
train_set <- read_table2(data_path, col_names = FALSE, col_types = cols(X27 = "_"))
glimpse(train_set)
var_names <- c("engine", "cycles", "op_setting_1", "op_setting_2", "op_setting_3",
paste0("sensor_", 1:21))
names(train_set) <- var_names
train_set$engine <- factor(train_set$engine)
# add a Time to Event variable
add_tte <- function(dataset){
dataset %<>% group_by(engine) %>% mutate(tte = max(cycles) - cycles) %>% ungroup
}
train_set <- add_tte(train_set)
stats_train <- skim(train_set)
kable(stats_train)
library(skimr)
stats_train <- skim(train_set)
kable(stats_train)
op_settings <- train_set %>% select(engine, cycles, starts_with("op")) %>%
gather(key = setting, value = measurement, -engine, -cycles)
ggplot(op_settings, aes(x = cycles, y =  measurement)) +
geom_line(aes(group = engine), alpha = 0.1) +
geom_smooth(se = FALSE) +
facet_wrap(~ setting, scales = "free_y")
library(knitr)
library(readr)
library(ggplot2)
library(tools)
library(magrittr)
library(skimr)
library(dplyr)
library(tidyr)
library(viridis)
op_settings <- train_set %>% select(engine, cycles, starts_with("op")) %>%
gather(key = setting, value = measurement, -engine, -cycles)
ggplot(op_settings, aes(x = cycles, y =  measurement)) +
geom_line(aes(group = engine), alpha = 0.1) +
geom_smooth(se = FALSE) +
facet_wrap(~ setting, scales = "free_y")
tte <- train_set %>% select(engine, cycles, tte) %>% group_by(engine) %>%
summarize(TTE = tte[1])
nbins = nclass.FD(tte$TTE)
ggplot(tte, aes(x = TTE, y = ..density..)) +
geom_histogram(col = "red", fill = "green", alpha = 0.2, bins = nbins) +
geom_density(col = "red", size = 1)
mean_tte <- mean(tte$TTE)
sd_tte   <- sd(tte$TTE)
normal_percentile_975 <- qnorm(p = 0.975, mean_tte, sd_tte)
actual_percentile_975 <- quantile(tte$TTE, probs = 0.975)
normal_percentile_975
actual_percentile_975
sample_train_set <- train_set %>% filter(engine %in% sample(engine, 10))
sample_train_set_tall <- sample_train_set %>%
gather(key = sensor, value = measurement, -engine, -cycles, -starts_with("op"), -tte)
ggplot(sample_train_set_tall, aes(x = cycles, y =  measurement, color = engine)) +
geom_line() +
geom_smooth(se = FALSE) +
scale_color_viridis(discrete = TRUE) +
facet_wrap(~ sensor, scales = "free_y")
history()
ensors <- train_set %>% select(-starts_with("op"), -tte) %>%
gather(key = sensor, value = measurement, -engine, -cycles)
ggplot(sensors, aes(x = cycles, y =  measurement)) +
geom_line(aes(group = engine), alpha = 0.025) +
facet_wrap(~ sensor, scales = "free_y")
sensors <- train_set %>% select(-starts_with("op"), -tte) %>%
gather(key = sensor, value = measurement, -engine, -cycles)
ggplot(sensors, aes(x = cycles, y =  measurement)) +
geom_line(aes(group = engine), alpha = 0.025) +
facet_wrap(~ sensor, scales = "free_y")
sensors <- train_set %>% select(-starts_with("op"), -tte) %>%
gather(key = sensor, value = measurement, -engine, -cycles)
ggplot(sensors, aes(x = cycles, y =  measurement)) +
geom_line(aes(group = engine), alpha = 0.025) +
facet_wrap(~ sensor, scales = "free_y")
